import pandas as pd
import mifs
import numpy as np
import csv
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification, make_regression


def load_data(filename):
    dataset = list()
    with open(filename,'r') as filen:
        data_reader = csv.reader(filen)
        for row in data_reader:
            if not row:
                continue
            dataset.append(row)
        dataset.pop(0)
    return dataset

def loadCsv(filename):
    lines = csv.reader(open(filename, "rb"))
    dataset = list(lines)
    for i in range(len(dataset)):
        dataset[i] = [float(x) for x in dataset[i]]
    return dataset

def label_to_int(dataset,rows,cols):
    for i in range(rows):
        for j in range(cols):
            if(dataset[i][j]=="benign"):
                dataset[i][j]=0
            elif (dataset[i][j]=="virus"):
                dataset[i][j]=1
'''def label_to_int(dataset,rows,cols):
    for i in range(rows):
        if(dataset[i][cols-1]=="Iris-setosa"):
            dataset[i][cols-1]=0;
        else:
            #elif (dataset[i][j]=="No"):
            dataset[i][cols-1]=1;'''

def string_to_float(dataset,rows,cols):
    for i in range(rows):
        for j in range(cols):
            dataset[i][j]=int(dataset[i][j])

'''def string_to_float(dataset,rows,cols):
    for i in range(rows):
        for j in range(cols):
            dataset[i][j]=float(dataset[i][j])'''


'''filename = 'dataset.csv'

dataset = load_data(filename)
rows = len(dataset)
cols = len(dataset[0])
label_to_int(dataset,rows,cols)
string_to_float(dataset,rows,cols)

X=[]
y=[]
for i in range(rows):
    y.append(dataset[i][-1])
    del(dataset[i][-1])
    X.append(dataset[i])
print X
print "########################################################"
print y



# define MI_FS feature selection method
feat_selector = mifs.MutualInformationFeatureSelector()

# find all relevant features
feat_selector.fit(X, y)

# check selected features
feat_selector.support_

# check ranking of features
feat_selector.ranking_

# call transform() on X to filter it down to selected features
X_filtered = feat_selector.transform(X)'''


def check_selection(selected, i, r):
    """
    Check FN, FP, TP ratios among the selected features.
    """
    # reorder selected features
    try:
        selected = set(selected)
        all_f = set(range(i+r))
        TP = len(selected.intersection(all_f))
        FP = len(selected - all_f)
        FN = len(all_f - selected)
        if (TP+FN) > 0:
            sens = TP/float(TP + FN)
        else:
            sens = np.nan
        if (TP+FP) > 0:
            prec =TP/float(TP + FP)
        else:
            prec = np.nan
    except:
        sens = np.nan
        prec = np.nan
    return sens, prec
    
   
filename = 'dataset.csv'
dataset = load_data(filename)
rows = len(dataset)
cols = len(dataset[0])
label_to_int(dataset,rows,cols)
string_to_float(dataset,rows,cols)
f=len(dataset[0])-1
s=len(dataset)
X=[]
y=[]
for i in range(rows):
    y.append(dataset[i][-1])
    del(dataset[i][-1])
    X.append(dataset[i])
i = int(.1*f)
r = int(.05*f)
c = 2

# simulate dataset with discrete class labels in y
#X, y = make_classification(n_samples=s, n_features=f, n_informative=i,n_redundant=r, n_clusters_per_class=c,random_state=0, shuffle=False)
# perform feature selection
X=np.array(X)
y=np.array(y)
print X
print y
MIFS = mifs.MutualInformationFeatureSelector(method='JMI', verbose=2)
print "111"
MIFS.fit(X,y)
print "123"
# calculate precision and sensitivity
sens, prec = check_selection(np.where(MIFS.support_)[0], i, r)
print 'Sensitivity: ' + str(sens) + '    Precision: ' + str(prec)


X, y = make_regression(n_samples=s, n_features=f, n_informative=i,random_state=0, shuffle=False)
MIFS = mifs.MutualInformationFeatureSelector(method='JMI', verbose=2,categorical=False)
MIFS.fit(X,y)
# calculate precision and sensitivity
sens, prec = check_selection(np.where(MIFS.support_)[0], i, r)
print 'Sensitivity: ' + str(sens) + '    Precision: ' + str(prec)
